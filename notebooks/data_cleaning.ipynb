{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utah Real Estate Market Analysis: Sales Trends and Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Utah Real Estate Sales Analysis project aims to leverage a dataset containing detailed real estate listings from Utah to explore market trends, pricing dynamics, and key property characteristics influencing sales prices. The dataset provides comprehensive information about 4,440 unique real estate listings, including attributes such as property type, size, listing price, bedrooms, bathrooms, lot size, garage spaces, and the date of last sale. By analyzing this data, we seek to gain insights into the Utah real estate market and develop predictive models to estimate property prices based on various features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "As previously mentioned, the dataset used in this analysis is sourced from Utah real estate listings and provides detailed information for 4,440 properties, which were built as early as 1860 to 2026 for future listings. The dataset allows for a comprehensive analysis of factors influencing property values and trends within Utahâ€™s real estate market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load the Datasets\n",
    "During this process, we will load and prepare our data for an exploratory data analysis by gaining key insights from our data by taking a general look (.head), checking for missing values (.info), and a brief summary of statistics (.describe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and load the data with panda\n",
    "import pandas as pd\n",
    "path = '../data/real_estate_utah.csv'\n",
    "real_estate_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Understanding the Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Estate Data Key Features\n",
    "Column Descriptors (Pulled from Kaggle)\n",
    "- type: Type of property (e.g., single_family, land)\n",
    "- text: Description of the property\n",
    "- year_built: Year the property was built\n",
    "- beds: Number of bedrooms\n",
    "- baths: Total number of bathrooms\n",
    "- baths_full: Number of full bathrooms\n",
    "- baths_half: Number of half bathrooms\n",
    "- garage: Number of garage spaces\n",
    "- lot_sqft: Lot size in square feet\n",
    "- sqft: Property size in square feet\n",
    "- stories: Number of stories\n",
    "- lastSoldOn: Date the property was last sold\n",
    "- listPrice: Listing price of the property\n",
    "- status: Current status of the property (e.g., for_sale)\n",
    "\n",
    "Key Data Insights based on Summary Stats from .describe:\n",
    "- potential outliers in the sqft, lot_sqft, and listPrice columns\n",
    "- Data types are generally correct except for lastSoldOn, type, and status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Initial exploration reveals possible outliers in variables like lot_sqft, sqft, and listPrice, with some unusually high values that may skew analysis. Handling these outliers will involve filtering or capping based on the overall distribution. The lastSoldOn column, representing dates, will be transformed into a more analytical format (e.g., extracting year or month). For categorical variables like type and status, label encoding or one-hot encoding will be applied based on the context of each analysis. After completing these transformations, the cleaned dataset will be exported in a standardized format for seamless integration with other analysis notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Handle Missing Values\n",
    "Our .info does not show any current missing null values, but for a sanity check let's take a look for null values again in case we missed anything using isnull() and sum() to identify columns with missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Detect and Removing Outliers\n",
    "Potential outliers with abnormally high values that might affect the study were found in the lot_sqft, sqft, and listPrice columns during preliminary investigation. Depending on the distribution of the data, we will identify these outliers and implement filtering or capping using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set thresholds based on percentiles to cap or filter out extreme values\n",
    "cap_thresholds = {\n",
    "    'lot_sqft': np.percentile(real_estate_data['lot_sqft'], 99),\n",
    "    'sqft': np.percentile(real_estate_data['sqft'], 99),\n",
    "    'listPrice': np.percentile(real_estate_data['listPrice'], 99)\n",
    "}\n",
    "\n",
    "# Capping outliers at the 99th percentile\n",
    "real_estate_data['lot_sqft'] = np.where(real_estate_data['lot_sqft'] > cap_thresholds['lot_sqft'], cap_thresholds['lot_sqft'], real_estate_data['lot_sqft'])\n",
    "real_estate_data['sqft'] = np.where(real_estate_data['sqft'] > cap_thresholds['sqft'], cap_thresholds['sqft'], real_estate_data['sqft'])\n",
    "real_estate_data['listPrice'] = np.where(real_estate_data['listPrice'] > cap_thresholds['listPrice'], cap_thresholds['listPrice'], real_estate_data['listPrice'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check summary statistics again after capping to see if extreme values remain\n",
    "real_estate_data[['lot_sqft', 'sqft', 'listPrice']].describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After handling the outliers, it appears that extreme values in \"lot_sqft,\" \"sqft,\" and \"listPrice\" have been capped. The maximum values have been significantly reduced, especially in the \"lot_sqft\" and \"listPrice\" columns, where the original maximums were in the range of tens of millions, but the capped values are much lower, under 7 million for \"listPrice\" and around 6 million for \"lot_sqft.\" The 99th percentile also shows more reasonable values after capping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Date Standardization for lastSoldOn Column\n",
    "The lastSoldOn column, representing dates, will be converted to DateTime format, allowing extraction of specific components like year and month for deeper time-based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'lastSoldOn' to datetime\n",
    "real_estate_data['lastSoldOn'] = pd.to_datetime(real_estate_data['lastSoldOn'], errors='coerce')\n",
    "\n",
    "# Extract year and month for analysis\n",
    "real_estate_data['sold_year'] = real_estate_data['lastSoldOn'].dt.year\n",
    "real_estate_data['sold_month'] = real_estate_data['lastSoldOn'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for new columns\n",
    "real_estate_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Encoding Categorical Variables\n",
    "Categorical variables like type and status will be encoded. For variables with ordinal significance, label encoding will be used, while one-hot encoding will apply for nominal categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the Type Column:\n",
    "We are going to create a new column that categorizes the 'type' column into individual property types compared to \"Other\". For example, if the property type is \"Single Family\", it will remain as \"Single Family\", but if it's any other type, it will be classified as \"Other\". We are doing this to keep the original type column to answer questions for EDA, but drop it once we get to constructing the machine learning model. Perform one-hot encoding on the \"type\" column to create separate columns for each individual type. Concatenate both the new comparison column and the one-hot encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new 'type_comparison' column where each 'type' is compared to 'Other'\n",
    "real_estate_data['type_comparison'] = real_estate_data['type'].apply(lambda x: x if x == 'Single Family' else 'Other')\n",
    "\n",
    "# One-hot encoding for the 'type' column (original categorical column)\n",
    "type_dummies = pd.get_dummies(real_estate_data['type'], prefix='type')\n",
    "\n",
    "# Concatenate the new column and the one-hot encoded columns with the original DataFrame\n",
    "real_estate_data = pd.concat([real_estate_data, type_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the Status Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the label encoding the status: 0 represents if the property is for sale and 1 represents if the property is ready to build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status_encoded\n",
       "0    4185\n",
       "1     255\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label Encoding for ordinal categories (status)\n",
    "label_encoder = LabelEncoder()\n",
    "real_estate_data['status_encoded'] = label_encoder.fit_transform(real_estate_data['status'])\n",
    "real_estate_data['status_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Exporting the Cleaned Dataset\n",
    "After completing these transformations, the cleaned dataset will be exported in a standardized format to integrate seamlessly with other analysis notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohort_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
