{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis without Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The goal of this machine learning analysis is to develop a predictive model for estimating real estate listing prices in Utah. We’ll employ a variety of regression techniques, including Linear Regression, Decision Trees, and Ensemble methods, to assess model accuracy and identify the best predictors of property price. By refining the model with features such as price-per-square-foot and property age, we aim to provide accurate and actionable insights that real estate professionals, investors, and analysts can use to gauge property values effectively.\n",
    "\n",
    "As a reminder goal is to find out:\n",
    "\n",
    "- Which features best predict listing prices.\n",
    "- How accurately different models can predict these prices.\n",
    "- How much we can improve accuracy by tuning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Analysis Questions\n",
    "- What are the best predictors of listing price among the property features?\n",
    "- How accurately can we predict the list price based on property attributes?\n",
    "- How do different regression models compare in predicting the listing price?\n",
    "- What are the residuals and their distribution for the best-performing model?\n",
    "- Does model performance improve significantly with hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Data preparation is a crucial step where we get our data ready for modeling. This includes dividing the data into training and testing sets, scaling (or resizing) the numerical data, and encoding (or converting) the categorical data (like property type) into a format the model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Clean & Transformed Data\n",
    "path = ('../data/cleaned_real_estate_utah.csv')\n",
    "cleanedrs_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Outliers \n",
    "\n",
    "In machine learning, outliers can significantly impact model performance, especially for certain algorithms. Removing or handling them correctly can help improve prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4440 entries, 0 to 4439\n",
      "Data columns (total 29 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   type                              4440 non-null   object \n",
      " 1   text                              4440 non-null   object \n",
      " 2   year_built                        4440 non-null   float64\n",
      " 3   beds                              4440 non-null   float64\n",
      " 4   baths                             4440 non-null   float64\n",
      " 5   baths_full                        4440 non-null   float64\n",
      " 6   baths_half                        4440 non-null   float64\n",
      " 7   garage                            4440 non-null   float64\n",
      " 8   lot_sqft                          4440 non-null   float64\n",
      " 9   sqft                              4440 non-null   float64\n",
      " 10  stories                           4440 non-null   float64\n",
      " 11  lastSoldOn                        4440 non-null   object \n",
      " 12  listPrice                         4440 non-null   float64\n",
      " 13  status                            4440 non-null   object \n",
      " 14  sold_year                         4440 non-null   int64  \n",
      " 15  sold_month                        4440 non-null   int64  \n",
      " 16  type_comparison                   4440 non-null   object \n",
      " 17  type_condo                        4440 non-null   bool   \n",
      " 18  type_condo_townhome               4440 non-null   bool   \n",
      " 19  type_condo_townhome_rowhome_coop  4440 non-null   bool   \n",
      " 20  type_condos                       4440 non-null   bool   \n",
      " 21  type_farm                         4440 non-null   bool   \n",
      " 22  type_land                         4440 non-null   bool   \n",
      " 23  type_mobile                       4440 non-null   bool   \n",
      " 24  type_other                        4440 non-null   bool   \n",
      " 25  type_single_family                4440 non-null   bool   \n",
      " 26  type_townhomes                    4440 non-null   bool   \n",
      " 27  type_townhouse                    4440 non-null   bool   \n",
      " 28  status_encoded                    4440 non-null   int64  \n",
      "dtypes: bool(11), float64(10), int64(3), object(5)\n",
      "memory usage: 672.2+ KB\n"
     ]
    }
   ],
   "source": [
    "cleanedrs_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Outliers using IQR (Pulled from Kaggle)\n",
    "def remove_outliers_iqr(cleanedrs_data, columns):\n",
    "    \"\"\"\n",
    "    Remove outliers from the specified columns in the DataFrame using the IQR technique.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    columns (list): A list of column names to check for outliers.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        Q1 = cleanedrs_data[column].quantile(0.25)\n",
    "        Q3 = cleanedrs_data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - (1.5 * IQR)\n",
    "        upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "        cleanedrs_data = cleanedrs_data[(cleanedrs_data[column] >= lower_bound) & (cleanedrs_data[column] <= upper_bound)]\n",
    "\n",
    "    return cleanedrs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['beds', 'baths', 'sqft', 'listPrice', \"lot_sqft\"]\n",
    "cleanedrs_data = remove_outliers_iqr(cleanedrs_data, columns_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2858 entries, 0 to 2857\n",
      "Data columns (total 29 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   type                              2858 non-null   object \n",
      " 1   text                              2858 non-null   object \n",
      " 2   year_built                        2858 non-null   float64\n",
      " 3   beds                              2858 non-null   float64\n",
      " 4   baths                             2858 non-null   float64\n",
      " 5   baths_full                        2858 non-null   float64\n",
      " 6   baths_half                        2858 non-null   float64\n",
      " 7   garage                            2858 non-null   float64\n",
      " 8   lot_sqft                          2858 non-null   float64\n",
      " 9   sqft                              2858 non-null   float64\n",
      " 10  stories                           2858 non-null   float64\n",
      " 11  lastSoldOn                        2858 non-null   object \n",
      " 12  listPrice                         2858 non-null   float64\n",
      " 13  status                            2858 non-null   object \n",
      " 14  sold_year                         2858 non-null   int64  \n",
      " 15  sold_month                        2858 non-null   int64  \n",
      " 16  type_comparison                   2858 non-null   object \n",
      " 17  type_condo                        2858 non-null   bool   \n",
      " 18  type_condo_townhome               2858 non-null   bool   \n",
      " 19  type_condo_townhome_rowhome_coop  2858 non-null   bool   \n",
      " 20  type_condos                       2858 non-null   bool   \n",
      " 21  type_farm                         2858 non-null   bool   \n",
      " 22  type_land                         2858 non-null   bool   \n",
      " 23  type_mobile                       2858 non-null   bool   \n",
      " 24  type_other                        2858 non-null   bool   \n",
      " 25  type_single_family                2858 non-null   bool   \n",
      " 26  type_townhomes                    2858 non-null   bool   \n",
      " 27  type_townhouse                    2858 non-null   bool   \n",
      " 28  status_encoded                    2858 non-null   int64  \n",
      "dtypes: bool(11), float64(10), int64(3), object(5)\n",
      "memory usage: 432.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cleanedrs_data.reset_index(drop=True, inplace=True)\n",
    "cleanedrs_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining X and y\n",
    "In the data preparation for machine learning, we need to specify:\n",
    "\n",
    "- X: The features or independent variables, which will include all relevant property attributes that may predict listing price (like square footage, number of bedrooms, and any encoded columns for categorical features).\n",
    "- y: The target or dependent variable, which in this case is the listing price (listPrice), as we are trying to predict this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable y as the listing price\n",
    "y = cleanedrs_data['listPrice']\n",
    "\n",
    "# Define feature matrix X, selecting only the relevant columns\n",
    "# Here we drop columns that aren't needed for prediction like 'listPrice' and the original categorical columns\n",
    "X = cleanedrs_data.drop([\n",
    "    'listPrice',           # Target variable\n",
    "    'type',                # Original categorical column\n",
    "    'status',              # Original categorical column\n",
    "    'text',                # Text data\n",
    "    'lastSoldOn',          # Date information, potentially unnecessary\n",
    "    'type_comparison',     # Non-numeric comparison column\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set y to be listPrice, as this is our target variable.\n",
    "X includes all features, but excludes listPrice (since it’s our target) and the original unencoded columns for type and status, as we have already created encoded versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training & Testing Sets:\n",
    "- The training set is used to teach the model.\n",
    "- The testing set checks if the model can accurately predict new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data (assuming 'X' are the features and 'y' is the target variable, listPrice)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 80% of our data for training and 20% for testing, which is common for predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Numerical Features:\n",
    "- To help the model perform better, we scale features like square footage, which might have a large range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features (fit on train data, transform on both train and test data)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling makes sure that big numbers (like 2000 sqft) don’t overpower smaller numbers, helping the model learn relationships more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features\n",
    "Since we handled encoding earlier, here’s how to confirm we’re using the processed data:\n",
    "\n",
    "type_comparison and any additional one-hot columns we created for type are now in X.\n",
    "status_encoded is also in X, which contains ordinal encoding for the status column.\n",
    "If we did these steps earlier, we don’t need to encode type or status again. We can proceed directly to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Example to Encode Categorical Features (already completed in data cleaning step 2.4)\n",
    "# # Encode categorical features\n",
    "# categorical_features = ['propertyType', 'status']\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('cat', OneHotEncoder(), categorical_features)],\n",
    "#     remainder='passthrough')\n",
    "\n",
    "# X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "# X_test_prepared = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding converts text categories into numbers so the model can process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scaled data back to DataFrames with the original column names for easy reference\n",
    "X_train_prepared = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_prepared = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Structure of X and y\n",
    "This section ensures that we’re only using the encoded columns, without redundancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X): Index(['year_built', 'beds', 'baths', 'baths_full', 'baths_half', 'garage',\n",
      "       'lot_sqft', 'sqft', 'stories', 'sold_year', 'sold_month', 'type_condo',\n",
      "       'type_condo_townhome', 'type_condo_townhome_rowhome_coop',\n",
      "       'type_condos', 'type_farm', 'type_land', 'type_mobile', 'type_other',\n",
      "       'type_single_family', 'type_townhomes', 'type_townhouse',\n",
      "       'status_encoded'],\n",
      "      dtype='object')\n",
      "Target (y): listPrice\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of X and y to verify\n",
    "print(\"Features (X):\", X.columns)\n",
    "print(\"Target (y):\", y.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step confirms the columns in X match our expectations for the features we want to include and are ready for training.\n",
    "\n",
    "By following these adjustments, our machine learning model should now use the prepared data directly, with all required encoding already applied. This approach keeps the workflow clean and efficient without duplicating steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "In this step, we’ll train several models to see which ones perform best. A “shotgun approach” means we test many models to find which gives the best initial results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Multiple Regression Models:\n",
    "- We’ll train six to eight base models and evaluate their performance. Common models include:\n",
    "  - Linear Regression\n",
    "  - Decision Tree Regressor\n",
    "  - Random Forest Regressor\n",
    "  - Gradient Boosting Regressor\n",
    "  - Ridge and Lasso Regression (for regularization)\n",
    "  - K-Nearest Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression score: 0.5954785535268682\n",
      "Ridge Regression score: 0.5936141241222923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.369e+11, tolerance: 1.070e+10\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression score: 0.593592395639175\n",
      "Decision Tree score: 0.4417947116744324\n",
      "Random Forest score: 0.6294803498982293\n",
      "Gradient Boosting score: 0.6267016512326129\n",
      "K-Nearest Neighbors score: 0.5896317604827508\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Fit each model on the training data and store the results\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_prepared, y_train)\n",
    "    results[model_name] = model.score(X_test_prepared, y_test)\n",
    "    print(f\"{model_name} score: {results[model_name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train and evaluate each model, storing each model’s score to compare which predicts listing prices best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation:\n",
    "- Cross-validation gives a more reliable estimate of model performance by testing on different subsets of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Cross-Validation Score: -5.602364997140645e+23\n",
      "Ridge Regression Cross-Validation Score: 0.6346991857135033\n",
      "Lasso Regression Cross-Validation Score: 0.6346467917879364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.238e+11, tolerance: 8.524e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+12, tolerance: 8.675e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.822e+11, tolerance: 8.661e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.693e+11, tolerance: 8.416e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.382e+11, tolerance: 8.530e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Cross-Validation Score: 0.44503086903025074\n",
      "Random Forest Cross-Validation Score: 0.6504587799418824\n",
      "Gradient Boosting Cross-Validation Score: 0.6584404467453725\n",
      "K-Nearest Neighbors Cross-Validation Score: 0.5972124681217272\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate for each model\n",
    "for model_name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train_prepared, y_train, cv=5)\n",
    "    print(f\"{model_name} Cross-Validation Score: {cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation:\n",
    "Now, we assess each model’s accuracy using metrics that measure how close the predictions are to actual prices.\n",
    "\n",
    "Evaluation Metrics:\n",
    "\n",
    "- Mean Absolute Error (MAE) and Mean Squared Error (MSE) show prediction accuracy. Lower values mean better performance.\n",
    "- R-squared measures how well the model explains the price variation; closer to 1 is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 90475.15458259117\n",
      "Mean Squared Error: 16316844030.432077\n",
      "R-squared: 0.6260565650171691\n"
     ]
    }
   ],
   "source": [
    "# Define and train the Gradient Boosting model\n",
    "best_model = GradientBoostingRegressor()  \n",
    "best_model.fit(X_train_prepared, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model.predict(X_test_prepared)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning:\n",
    "- We improve the model by adjusting its settings, like the number of trees in a forest. This helps the model learn better patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20]\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_prepared, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression, Ridge Regression, Lasso Regression\n",
    "While these models don't have many hyperparameters to tune, Ridge and Lasso have a hyperparameter for regularization strength (alpha). For Linear Regression, no hyperparameter tuning is needed, but for Ridge and Lasso, we can tune alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Ridge: {'alpha': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.236e+11, tolerance: 8.524e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+12, tolerance: 8.675e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.821e+11, tolerance: 8.661e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.370e+12, tolerance: 8.416e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.380e+11, tolerance: 8.530e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.238e+11, tolerance: 8.524e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+12, tolerance: 8.675e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.822e+11, tolerance: 8.661e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.693e+11, tolerance: 8.416e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.382e+11, tolerance: 8.530e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.253e+11, tolerance: 8.524e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.657e+11, tolerance: 8.675e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.838e+11, tolerance: 8.661e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.708e+11, tolerance: 8.416e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.397e+11, tolerance: 8.530e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Lasso: {'alpha': 100}\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters for Ridge Regression\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1, 10, 100]  # Regularization strength\n",
    "}\n",
    "grid_search_ridge = GridSearchCV(Ridge(), param_grid_ridge, cv=5)\n",
    "grid_search_ridge.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for Ridge:\", grid_search_ridge.best_params_)\n",
    "\n",
    "# Tuning hyperparameters for Lasso Regression\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.1, 1, 10, 100]  # Regularization strength\n",
    "}\n",
    "grid_search_lasso = GridSearchCV(Lasso(), param_grid_lasso, cv=5)\n",
    "grid_search_lasso.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for Lasso:\", grid_search_lasso.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor \n",
    "The Decision Tree Regressor has hyperparameters like max_depth, min_samples_split, and min_samples_leaf that can be tuned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Decision Tree: {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters for Decision Tree\n",
    "param_grid_tree = {\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "grid_search_tree = GridSearchCV(DecisionTreeRegressor(), param_grid_tree, cv=5)\n",
    "grid_search_tree.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for Decision Tree:\", grid_search_tree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) \n",
    "For KNN, the hyperparameter n_neighbors can be tuned. We might also want to tune weights (whether the algorithm should use uniform or distance-based weighting) and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for KNN: {'metric': 'manhattan', 'n_neighbors': 20, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters for K-Nearest Neighbors (KNN)\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 10, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "grid_search_knn = GridSearchCV(KNeighborsRegressor(), param_grid_knn, cv=5)\n",
    "grid_search_knn.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for KNN:\", grid_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor\n",
    "For Gradient Boosting, we can tune n_estimators, learning_rate, max_depth, and other parameters to improve the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters for Gradient Boosting\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search_gb = GridSearchCV(GradientBoostingRegressor(), param_grid_gb, cv=5)\n",
    "grid_search_gb.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for Gradient Boosting:\", grid_search_gb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-train each model with the best hyperparameters\n",
    "\n",
    "# For Ridge\n",
    "best_ridge = Ridge(alpha=grid_search_ridge.best_params_['alpha'])\n",
    "best_ridge.fit(X_train_prepared, y_train)\n",
    "\n",
    "# For Lasso\n",
    "best_lasso = Lasso(alpha=grid_search_lasso.best_params_['alpha'])\n",
    "best_lasso.fit(X_train_prepared, y_train)\n",
    "\n",
    "# For Decision Tree\n",
    "best_tree = DecisionTreeRegressor(\n",
    "    max_depth=grid_search_tree.best_params_['max_depth'],\n",
    "    min_samples_split=grid_search_tree.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=grid_search_tree.best_params_['min_samples_leaf']\n",
    ")\n",
    "best_tree.fit(X_train_prepared, y_train)\n",
    "\n",
    "# For KNN\n",
    "best_knn = KNeighborsRegressor(\n",
    "    n_neighbors=grid_search_knn.best_params_['n_neighbors'],\n",
    "    weights=grid_search_knn.best_params_['weights'],\n",
    "    metric=grid_search_knn.best_params_['metric']\n",
    ")\n",
    "best_knn.fit(X_train_prepared, y_train)\n",
    "\n",
    "# For Gradient Boosting\n",
    "best_gb = GradientBoostingRegressor(\n",
    "    n_estimators=grid_search_gb.best_params_['n_estimators'],\n",
    "    learning_rate=grid_search_gb.best_params_['learning_rate'],\n",
    "    max_depth=grid_search_gb.best_params_['max_depth']\n",
    ")\n",
    "best_gb.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Model - MAE: 95894.45696912776, MSE: 17723240375.61023, R2: 0.593825290434759\n",
      "Lasso Model - MAE: 95864.88877000447, MSE: 17720441854.583485, R2: 0.593889425911182\n",
      "Decision Tree Model - MAE: 95365.31886472329, MSE: 17819355321.696323, R2: 0.5916225634229918\n",
      "KNN Model - MAE: 86370.57462917086, MSE: 16333198611.139946, R2: 0.6256817567468811\n",
      "Gradient Boosting Model - MAE: 90361.27640106423, MSE: 16280128262.65163, R2: 0.6268980034899673\n"
     ]
    }
   ],
   "source": [
    "# For Ridge\n",
    "y_pred_ridge = best_ridge.predict(X_test_prepared)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "print(f\"Ridge Model - MAE: {mae_ridge}, MSE: {mse_ridge}, R2: {r2_ridge}\")\n",
    "\n",
    "# For Lasso\n",
    "y_pred_lasso = best_lasso.predict(X_test_prepared)\n",
    "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "print(f\"Lasso Model - MAE: {mae_lasso}, MSE: {mse_lasso}, R2: {r2_lasso}\")\n",
    "\n",
    "# For Decision Tree\n",
    "y_pred_tree = best_tree.predict(X_test_prepared)\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree Model - MAE: {mae_tree}, MSE: {mse_tree}, R2: {r2_tree}\")\n",
    "\n",
    "# For KNN\n",
    "y_pred_knn = best_knn.predict(X_test_prepared)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "print(f\"KNN Model - MAE: {mae_knn}, MSE: {mse_knn}, R2: {r2_knn}\")\n",
    "\n",
    "# For Gradient Boosting\n",
    "y_pred_gb = best_gb.predict(X_test_prepared)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Model - MAE: {mae_gb}, MSE: {mse_gb}, R2: {r2_gb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Feature  Importance\n",
      "19                type_single_family    0.373987\n",
      "2                              baths    0.208360\n",
      "7                               sqft    0.193481\n",
      "5                             garage    0.074483\n",
      "17                       type_mobile    0.042903\n",
      "0                         year_built    0.030403\n",
      "6                           lot_sqft    0.029693\n",
      "9                          sold_year    0.011527\n",
      "10                        sold_month    0.010603\n",
      "8                            stories    0.008125\n",
      "1                               beds    0.005496\n",
      "3                         baths_full    0.005187\n",
      "20                    type_townhomes    0.002302\n",
      "14                       type_condos    0.001455\n",
      "22                    status_encoded    0.001433\n",
      "16                         type_land    0.000343\n",
      "13  type_condo_townhome_rowhome_coop    0.000160\n",
      "21                    type_townhouse    0.000061\n",
      "15                         type_farm    0.000000\n",
      "18                        type_other    0.000000\n",
      "12               type_condo_townhome    0.000000\n",
      "4                         baths_half    0.000000\n",
      "11                        type_condo    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract feature importance for the gradient boosting\n",
    "feature_importances = best_model.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(features, feature_importances)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance in Predicting Listing Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up a pipeline with scaling, feature engineering, and model tuning\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Experiment with MinMaxScaler, RobustScaler if needed\n",
    "    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),  # Optional, can tune degree\n",
    "    ('model', GradientBoostingRegressor())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.05],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__min_samples_split': [2, 5, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   5.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   5.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   5.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   5.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   5.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   6.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   6.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   6.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   6.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   6.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  12.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  12.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  12.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  13.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  13.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  16.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  17.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  18.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  17.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  16.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  20.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  18.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  19.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  18.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   5.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  17.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   5.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   5.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  20.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   5.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   5.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  19.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  20.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   6.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   6.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  19.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  19.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   6.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   6.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   6.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  10.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  10.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  10.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  11.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  11.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  14.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  13.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  14.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  14.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  14.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  17.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  17.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  17.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  17.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  17.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   6.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   7.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  23.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   8.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   8.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  23.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   6.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=   7.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=   8.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  24.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=   7.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  25.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  25.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=   7.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=   7.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  11.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  11.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  11.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  12.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  12.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  14.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  15.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  15.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  17.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  17.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  22.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  21.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  22.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  22.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  22.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  26.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  10.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  10.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  24.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  10.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  25.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  13.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  26.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  13.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=3, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  27.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  15.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  15.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  15.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  15.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  13.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  20.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  18.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  19.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  20.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  21.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  27.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  25.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  27.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  27.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  27.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  34.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  31.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  32.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  30.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  30.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   9.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   9.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   9.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  36.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   9.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  34.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   9.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  35.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  11.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  10.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  11.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  34.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  11.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  34.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  11.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  19.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  18.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  19.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  18.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  19.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  22.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  23.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  23.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  22.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  22.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  27.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  25.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  26.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  25.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  25.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   8.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  31.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   8.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   8.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   8.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  29.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  31.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=   8.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  10.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  10.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  11.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  32.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  11.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  32.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  12.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  19.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  18.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  19.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  18.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  18.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  20.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  22.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  21.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  21.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  21.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  26.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  25.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  26.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  26.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  26.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  12.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  33.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  12.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  13.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  32.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  33.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  13.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=  13.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  32.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=5, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  33.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  15.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  14.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  14.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  14.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=  14.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  22.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  21.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  22.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  22.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  22.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  28.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  26.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  31.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  36.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  37.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  43.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  45.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  45.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  45.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  45.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=  11.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=  12.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=  13.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  51.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=  14.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  46.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=  13.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  48.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  15.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  16.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  16.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  47.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  47.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  15.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=  15.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  23.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  22.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  23.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  22.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  25.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  31.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  33.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  33.5s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  34.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  34.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  40.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  39.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  38.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  35.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=0.8; total time=  35.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=  12.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=  11.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  43.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=  11.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=  11.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  40.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=0.8; total time=  11.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  43.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  15.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  14.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  45.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  16.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=5, model__n_estimators=300, model__subsample=1.0; total time=  46.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  17.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=100, model__subsample=1.0; total time=  18.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  28.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  25.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  27.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  26.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=0.8; total time=  26.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  32.2s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  34.0s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  32.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  33.6s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=200, model__subsample=1.0; total time=  34.8s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  41.7s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  40.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  41.3s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   5.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  39.4s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=0.8; total time=  39.6s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   6.3s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   6.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   7.0s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=0.8; total time=   7.4s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   7.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   8.3s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  50.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   7.1s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   7.1s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=100, model__subsample=1.0; total time=   7.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  47.2s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  11.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  48.2s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  10.4s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  11.3s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  11.3s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=0.8; total time=  12.1s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  48.9s\n",
      "[CV] END model__learning_rate=0.01, model__max_depth=7, model__min_samples_split=10, model__n_estimators=300, model__subsample=1.0; total time=  49.0s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  14.4s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  14.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  14.8s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  14.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=200, model__subsample=1.0; total time=  15.0s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  18.7s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  17.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  19.3s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  19.2s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=0.8; total time=  19.4s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   6.4s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   6.7s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   6.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  24.4s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  23.1s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   6.2s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  23.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   5.8s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   7.6s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   7.4s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  23.6s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=2, model__n_estimators=300, model__subsample=1.0; total time=  23.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   7.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   7.7s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=100, model__subsample=1.0; total time=   7.8s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  11.7s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  10.9s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  11.2s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  11.2s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=0.8; total time=  11.1s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  13.6s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  13.1s\n",
      "[CV] END model__learning_rate=0.1, model__max_depth=3, model__min_samples_split=5, model__n_estimators=200, model__subsample=1.0; total time=  13.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize GridSearchCV with cross-validation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_prepared, y_train)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Retrieve the best model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    966\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m         clone(base_estimator),\n\u001b[1;32m    968\u001b[0m         X,\n\u001b[1;32m    969\u001b[0m         y,\n\u001b[1;32m    970\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    971\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    972\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    973\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    974\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m )\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_prepared, y_train)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = best_model.predict(X_test_prepared)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Gradient Boosting Model Performance:\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Compare baseline and improved R-squared\n",
    "baseline_scores = {\n",
    "    'Gradient Boosting (Before Tuning)': 0.6566920833557454,\n",
    "    'Random Forest': 0.6196657954480231,\n",
    "    'Ridge Regression': 0.5361082110017976\n",
    "}\n",
    "improved_scores = {\n",
    "    'Gradient Boosting (After Tuning)': r2\n",
    "}\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(baseline_scores.keys(), baseline_scores.values(), color='skyblue', label='Baseline Scores')\n",
    "plt.bar(improved_scores.keys(), improved_scores.values(), color='salmon', label='Improved Scores')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"R-squared Score\")\n",
    "plt.title(\"Model Performance Before and After Tuning\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of predictions vs. actual values\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')  # Diagonal line\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs. Actual Property Prices\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohort_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
