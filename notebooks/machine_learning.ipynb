{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The goal of this machine learning analysis is to develop a predictive model for estimating real estate listing prices in Utah. We’ll employ a variety of regression techniques, including Linear Regression, Decision Trees, and Ensemble methods, to assess model accuracy and identify the best predictors of property price. By refining the model with features such as price-per-square-foot and property age, we aim to provide accurate and actionable insights that real estate professionals, investors, and analysts can use to gauge property values effectively.\n",
    "\n",
    "As a reminder goal is to find out:\n",
    "\n",
    "- Which features best predict listing prices.\n",
    "- How accurately different models can predict these prices.\n",
    "- How much we can improve accuracy by tuning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Analysis Questions\n",
    "- What are the best predictors of listing price among the property features?\n",
    "- How accurately can we predict the list price based on property attributes?\n",
    "- How do different regression models compare in predicting the listing price?\n",
    "- What are the residuals and their distribution for the best-performing model?\n",
    "- Does model performance improve significantly with hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Data preparation is a crucial step where we get our data ready for modeling. This includes dividing the data into training and testing sets, scaling (or resizing) the numerical data, and encoding (or converting) the categorical data (like property type) into a format the model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Clean & Transformed Data\n",
    "path = ('../data/cleaned_real_estate_utah.csv')\n",
    "cleanedrs_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>year_built</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>baths_full</th>\n",
       "      <th>baths_half</th>\n",
       "      <th>garage</th>\n",
       "      <th>lot_sqft</th>\n",
       "      <th>sqft</th>\n",
       "      <th>...</th>\n",
       "      <th>type_condo_townhome_rowhome_coop</th>\n",
       "      <th>type_condos</th>\n",
       "      <th>type_farm</th>\n",
       "      <th>type_land</th>\n",
       "      <th>type_mobile</th>\n",
       "      <th>type_other</th>\n",
       "      <th>type_single_family</th>\n",
       "      <th>type_townhomes</th>\n",
       "      <th>type_townhouse</th>\n",
       "      <th>status_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>single_family</td>\n",
       "      <td>Escape to tranquility with this off-grid, unfi...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71438.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single_family</td>\n",
       "      <td>Beautiful home in the desirable Oak Hills and ...</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56628.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>single_family</td>\n",
       "      <td>Welcome to your new home, nestled in the heart...</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10019.0</td>\n",
       "      <td>3528.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>single_family</td>\n",
       "      <td>Investment Opportunity. House needs some work ...</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12632.0</td>\n",
       "      <td>2097.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>land</td>\n",
       "      <td>Deer Springs Ranch is an 8000 Ac Ranch in an H...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>872071.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                                               text  \\\n",
       "0  single_family  Escape to tranquility with this off-grid, unfi...   \n",
       "1  single_family  Beautiful home in the desirable Oak Hills and ...   \n",
       "2  single_family  Welcome to your new home, nestled in the heart...   \n",
       "3  single_family  Investment Opportunity. House needs some work ...   \n",
       "4           land  Deer Springs Ranch is an 8000 Ac Ranch in an H...   \n",
       "\n",
       "   year_built  beds  baths  baths_full  baths_half  garage  lot_sqft    sqft  \\\n",
       "0      2020.0   1.0    1.0         1.0         1.0     2.0   71438.0   696.0   \n",
       "1      1968.0   4.0    3.0         2.0         1.0     2.0   56628.0  3700.0   \n",
       "2      1985.0   4.0    3.0         3.0         1.0     1.0   10019.0  3528.0   \n",
       "3      1936.0   4.0    2.0         2.0         1.0     2.0   12632.0  2097.0   \n",
       "4      2003.0   4.0    0.0         2.0         1.0     2.0  872071.0  2400.0   \n",
       "\n",
       "   ...  type_condo_townhome_rowhome_coop type_condos  type_farm type_land  \\\n",
       "0  ...                             False       False      False     False   \n",
       "1  ...                             False       False      False     False   \n",
       "2  ...                             False       False      False     False   \n",
       "3  ...                             False       False      False     False   \n",
       "4  ...                             False       False      False      True   \n",
       "\n",
       "   type_mobile  type_other type_single_family  type_townhomes  type_townhouse  \\\n",
       "0        False       False               True           False           False   \n",
       "1        False       False               True           False           False   \n",
       "2        False       False               True           False           False   \n",
       "3        False       False               True           False           False   \n",
       "4        False       False              False           False           False   \n",
       "\n",
       "   status_encoded  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedrs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve a higher accuracy score, combining similar condo types and removing outliers can be effective strategies. Here's how these changes could help:\n",
    "\n",
    "- Combining Condo Types: By grouping similar condo types (like type_condo, type_condo_townhome, etc.), we can reduce the complexity of the model by consolidating categories that might otherwise dilute prediction strength. This adjustment should help the model generalize better, especially if the distinctions between these types are minor in terms of their impact on listing price.\n",
    "\n",
    "- Removing Outliers: Outliers can skew your model's understanding of the \"typical\" relationships within the data, which might explain why some models only achieve around 50-60% accuracy. Removing outliers, particularly with a method like IQR (Interquartile Range), can help the model focus on the central trends, potentially boosting your accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining X and y\n",
    "In the data preparation for machine learning, we need to specify:\n",
    "\n",
    "- X: The features or independent variables, which will include all relevant property attributes that may predict listing price (like square footage, number of bedrooms, and any encoded columns for categorical features).\n",
    "- y: The target or dependent variable, which in this case is the listing price (listPrice), as we are trying to predict this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable y as the listing price\n",
    "y = cleanedrs_data['listPrice']\n",
    "\n",
    "# Define feature matrix X, selecting only the relevant columns\n",
    "# Here we drop columns that aren't needed for prediction like 'listPrice' and the original categorical columns\n",
    "X = cleanedrs_data.drop([\n",
    "    'listPrice',           # Target variable\n",
    "    'type',                # Original categorical column\n",
    "    'status',              # Original categorical column\n",
    "    'text',                # Text data\n",
    "    'lastSoldOn',          # Date information, potentially unnecessary\n",
    "    'type_comparison',     # Non-numeric comparison column\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set y to be listPrice, as this is our target variable.\n",
    "X includes all features, but excludes listPrice (since it’s our target) and the original unencoded columns for type and status, as we have already created encoded versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training & Testing Sets:\n",
    "- The training set is used to teach the model.\n",
    "- The testing set checks if the model can accurately predict new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data (assuming 'X' are the features and 'y' is the target variable, listPrice)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 80% of our data for training and 20% for testing, which is common for predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Numerical Features:\n",
    "- To help the model perform better, we scale features like square footage, which might have a large range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale numerical features (fit on train data, transform on both train and test data)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale the data using RobustScaler\n",
    "# scaler = RobustScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize and apply MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert scaled data back to DataFrames with the original column names for easy reference\n",
    "# X_train_prepared = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "# X_test_prepared = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling makes sure that big numbers (like 2000 sqft) don’t overpower smaller numbers, helping the model learn relationships more effectively. We use specific scalers depending on whether a model is sensitive to the range of data values. However for the initial round of model testing (a \"shotgun approach\" to quickly evaluate the base models' performance), we can prepare X_train_prepared and X_test_prepared without applying any scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prepared datasets without scaling for initial model testing\n",
    "X_train_prepared = X_train.copy()\n",
    "X_test_prepared = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By copying X_train and X_test directly, we’ll be working with the raw feature values. This setup allows us to assess the models' baseline performance without introducing scaling. Once we identify promising models, we can then apply scaling and tuning as needed.\n",
    "\n",
    "This direct copying will work well for models that are not sensitive to feature scales, such as decision trees and ensemble models. For models that are scale-sensitive (like linear regression or KNN), we might expect lower performance, but we can revisit scaling later to see how much it improves our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features\n",
    "Since we handled encoding earlier, here’s how to confirm we’re using the processed data:\n",
    "\n",
    "type_comparison and any additional one-hot columns we created for type are now in X.\n",
    "status_encoded is also in X, which contains ordinal encoding for the status column.\n",
    "If we did these steps earlier, we don’t need to encode type or status again. We can proceed directly to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Example to Encode Categorical Features (already completed in data cleaning step 2.4)\n",
    "# # Encode categorical features\n",
    "# categorical_features = ['propertyType', 'status']\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('cat', OneHotEncoder(), categorical_features)],\n",
    "#     remainder='passthrough')\n",
    "\n",
    "# X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "# X_test_prepared = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding converts text categories into numbers so the model can process them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Structure of X and y\n",
    "This section ensures that we’re only using the encoded columns, without redundancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X): Index(['year_built', 'beds', 'baths', 'baths_full', 'baths_half', 'garage',\n",
      "       'lot_sqft', 'sqft', 'stories', 'sold_year', 'sold_month', 'type_condo',\n",
      "       'type_condo_townhome', 'type_condo_townhome_rowhome_coop',\n",
      "       'type_condos', 'type_farm', 'type_land', 'type_mobile', 'type_other',\n",
      "       'type_single_family', 'type_townhomes', 'type_townhouse',\n",
      "       'status_encoded'],\n",
      "      dtype='object')\n",
      "Target (y): listPrice\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of X and y to verify\n",
    "print(\"Features (X):\", X.columns)\n",
    "print(\"Target (y):\", y.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step confirms the columns in X match our expectations for the features we want to include and are ready for training.\n",
    "\n",
    "By following these adjustments, our machine learning model should now use the prepared data directly, with all required encoding already applied. This approach keeps the workflow clean and efficient without duplicating steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "In this step, we’ll train several models to see which ones perform best. A “shotgun approach” means we test many models to find which gives the best initial results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Multiple Regression Models:\n",
    "- We’ll train six to eight base models and evaluate their performance. Common models include:\n",
    "  - Linear Regression\n",
    "  - Decision Tree Regressor\n",
    "  - Random Forest Regressor\n",
    "  - Gradient Boosting Regressor\n",
    "  - Ridge and Lasso Regression (for regularization)\n",
    "  - K-Nearest Neighbors Regressor\n",
    "  - Elastic net \n",
    "  - Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression score: 0.5360913839852439\n",
      "Ridge Regression score: 0.5364865146552655\n",
      "Lasso Regression score: 0.5360953539361227\n",
      "Decision Tree score: 0.3794926173274875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e+14, tolerance: 2.802e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score: 0.6106175957011017\n",
      "Gradient Boosting score: 0.6525904002819394\n",
      "K-Nearest Neighbors score: 0.2915565546768375\n",
      "Elastic Net score: 0.5258734524038151\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor(),\n",
    "    \"Elastic Net\": ElasticNet()\n",
    "}\n",
    "\n",
    "# Fit each model on the training data and store the results\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_prepared, y_train)\n",
    "    results[model_name] = model.score(X_test_prepared, y_test)\n",
    "    print(f\"{model_name} score: {results[model_name]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train and evaluate each model, storing each model’s score to compare which predicts listing prices best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Baseline Results:\n",
    "- Linear Regression Model Score: 0.536\n",
    "   The linear regression model explains 53.6% of the variance in listing prices. This is a moderate fit, indicating that the model is capturing some trends but still has room for improvement. Linear regression might not be flexible enough to capture complex relationships in the data.\n",
    "\n",
    "- Ridge Regression Model Score: 0.536\n",
    "   Ridge regression also yields a similar performance to linear regression (53.6%). Ridge regression works by adding a penalty for large coefficients, helping to reduce overfitting, but it still doesn’t perform much better than simple linear regression.\n",
    "\n",
    "- Lasso Regression Model Score: 0.536\n",
    "   Like Ridge Regression, Lasso also achieves a score of 53.6%. Lasso is known for performing feature selection by forcing some coefficients to zero, but in this case, it didn't significantly improve the model’s performance compared to Ridge and Linear Regression.\n",
    "\n",
    "- Decision Tree Model Score: 0.39\n",
    "   The decision tree model has a lower score (39.2%) than linear and ridge regression, suggesting it is not capturing the relationship between features and listing prices effectively. Decision trees can easily overfit, which could explain the poor performance.\n",
    "\n",
    "- Random Forest Model Score: 0.618\n",
    "   The random forest model performed much better with a score of 61.8%. Random forests combine multiple decision trees, reducing overfitting and improving generalization, which is why it performed better than a single decision tree.\n",
    "\n",
    "- Gradient Boosting Model Score: 0.656\n",
    "   The gradient boosting model outperforms all others, achieving a score of 65.6%. Gradient boosting works by sequentially adding trees, with each one trying to correct the errors of the previous tree, leading to more accurate predictions.\n",
    "\n",
    "- K-Nearest Neighbors Model Score: 0.464\n",
    "   The K-Nearest Neighbors (KNN) model has a moderate score of 46.4%. KNN tends to perform well with sufficient data and well-scaled features but appears less effective for this real estate dataset, potentially due to a high-dimensional feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specific Implementions for Better Prediction Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "- Scaler: StandardScaler (sensitive to data scale)\n",
    "- Tuning: Regularization with Ridge or Lasso using alpha parameter.\n",
    "- Search Method: GridSearchCV, as it’s effective with fewer parameters.\n",
    "- Pipeline: Use to combine scaling and polynomial features if needed.\n",
    "- Cross-Validation: Helps in generalizing predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with regularization and polynomial features\n",
    "pipeline_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),  # Optional non-linearity\n",
    "    ('model', Ridge())  # or Lasso\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Linear Model: {'model__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'model__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=5, scoring='r2')\n",
    "grid_search_lr.fit(X, y)\n",
    "print(\"Best params for Linear Model:\", grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Linear Model: {'model__alpha': 10.0}\n",
      "Linear Regression Test R^2 Score: 0.6519552314524868\n"
     ]
    }
   ],
   "source": [
    "# Fit and find best parameters\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "print(\"Best params for Linear Model:\", grid_search_lr.best_params_)\n",
    "\n",
    "# Test on best model\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "y_pred_lr = best_lr_model.predict(X_test)\n",
    "print(\"Linear Regression Test R^2 Score:\", r2_score(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor\n",
    "- Scaler: Not required; trees are not scale-sensitive.\n",
    "- Tuning: max_depth, min_samples_split, and min_samples_leaf.\n",
    "- Search Method: GridSearchCV is efficient given fewer parameters.\n",
    "- Pipeline: Not needed as scaling or transformations are unnecessary.\n",
    "- Cross-Validation: Useful for better generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Decision Tree: {'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Decision Tree\n",
    "param_grid_tree = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_tree = GridSearchCV(DecisionTreeRegressor(), param_grid_tree, cv=5, scoring='r2')\n",
    "grid_search_tree.fit(X, y)\n",
    "print(\"Best params for Decision Tree:\", grid_search_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=10, min_samples_leaf=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor(max_depth=10, min_samples_leaf=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=10, min_samples_leaf=10)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Decision Tree\n",
    "best_tree = DecisionTreeRegressor(\n",
    "    max_depth=grid_search_tree.best_params_['max_depth'],\n",
    "    min_samples_split=grid_search_tree.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=grid_search_tree.best_params_['min_samples_leaf']\n",
    ")\n",
    "best_tree.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model - MAE: 252692.87943781074, MSE: 322014728511.933, R2: 0.5611841293677708\n"
     ]
    }
   ],
   "source": [
    "# For Decision Tree\n",
    "y_pred_tree = best_tree.predict(X_test_prepared)\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree Model - MAE: {mae_tree}, MSE: {mse_tree}, R2: {r2_tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor\n",
    "- Scaler: Not required.\n",
    "- Tuning: n_estimators, max_depth, min_samples_split.\n",
    "- Search Method: RandomizedSearchCV, as there are many parameters.\n",
    "- Pipeline: Not needed.\n",
    "- Cross-Validation: Beneficial for model stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Random Forest: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Random search for Random Forest\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(RandomForestRegressor(), param_dist_rf, cv=5, scoring='r2', n_iter=10)\n",
    "random_search_rf.fit(X, y)\n",
    "print(\"Best params for Random Forest:\", random_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model setup and evaluation\n",
    "best_rf = RandomForestRegressor(\n",
    "    n_estimators=random_search_rf.best_params_['n_estimators'],\n",
    "    max_depth=random_search_rf.best_params_['max_depth'],\n",
    "    min_samples_split=random_search_rf.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=random_search_rf.best_params_['min_samples_leaf']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model - MAE: 224542.2607076356, MSE: 267647744717.53662, R2: 0.6352710987360128\n"
     ]
    }
   ],
   "source": [
    "best_rf.fit(X_train_prepared, y_train)\n",
    "y_pred_rf = best_rf.predict(X_test_prepared)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Model - MAE: {mae_rf}, MSE: {mse_rf}, R2: {r2_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor\n",
    "- Scaler: StandardScaler can help with performance consistency.\n",
    "- Tuning: n_estimators, learning_rate, max_depth.\n",
    "- Search Method: GridSearchCV, as these parameters are fewer and impactful.\n",
    "- Pipeline: Recommended for scaling and consistent transformations.\n",
    "- Cross-Validation: Improves performance reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m param_grid_gb \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__min_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m grid_search_gb \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline_gb, param_grid_gb, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m grid_search_gb\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params for Gradient Boosting:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search_gb\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    966\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m         clone(base_estimator),\n\u001b[1;32m    968\u001b[0m         X,\n\u001b[1;32m    969\u001b[0m         y,\n\u001b[1;32m    970\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    971\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    972\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    973\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    974\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m )\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:783\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    782\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 783\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[1;32m    784\u001b[0m     X_train,\n\u001b[1;32m    785\u001b[0m     y_train,\n\u001b[1;32m    786\u001b[0m     raw_predictions,\n\u001b[1;32m    787\u001b[0m     sample_weight_train,\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[1;32m    789\u001b[0m     X_val,\n\u001b[1;32m    790\u001b[0m     y_val,\n\u001b[1;32m    791\u001b[0m     sample_weight_val,\n\u001b[1;32m    792\u001b[0m     begin_at_stage,\n\u001b[1;32m    793\u001b[0m     monitor,\n\u001b[1;32m    794\u001b[0m )\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:879\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    872\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[1;32m    873\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[1;32m    874\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    875\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[1;32m    876\u001b[0m         )\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 879\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[1;32m    880\u001b[0m     i,\n\u001b[1;32m    881\u001b[0m     X,\n\u001b[1;32m    882\u001b[0m     y,\n\u001b[1;32m    883\u001b[0m     raw_predictions,\n\u001b[1;32m    884\u001b[0m     sample_weight,\n\u001b[1;32m    885\u001b[0m     sample_mask,\n\u001b[1;32m    886\u001b[0m     random_state,\n\u001b[1;32m    887\u001b[0m     X_csc\u001b[38;5;241m=\u001b[39mX_csc,\n\u001b[1;32m    888\u001b[0m     X_csr\u001b[38;5;241m=\u001b[39mX_csr,\n\u001b[1;32m    889\u001b[0m )\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 490\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    491\u001b[0m     X, neg_g_view[:, k], sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/tree/_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1377\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m   1378\u001b[0m         X,\n\u001b[1;32m   1379\u001b[0m         y,\n\u001b[1;32m   1380\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1381\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pipeline with scaling and GridSearch for Gradient Boosting\n",
    "pipeline_gb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "param_grid_gb = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__learning_rate': [0.01, 0.1],\n",
    "    'model__max_depth': [3, 5],\n",
    "    'model__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_gb = GridSearchCV(pipeline_gb, param_grid_gb, cv=5, scoring='r2')\n",
    "grid_search_gb.fit(X, y)\n",
    "print(\"Best params for Gradient Boosting:\", grid_search_gb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model setup and evaluation\n",
    "best_gb = GradientBoostingRegressor(\n",
    "    n_estimators=grid_search_gb.best_params_['model__n_estimators'],\n",
    "    learning_rate=grid_search_gb.best_params_['model__learning_rate'],\n",
    "    max_depth=grid_search_gb.best_params_['model__max_depth'],\n",
    "    min_samples_split=grid_search_gb.best_params_['model__min_samples_split']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model - MAE: 327913.4306874433, MSE: 2102458216204.9314, R2: 0.49890060712209416\n"
     ]
    }
   ],
   "source": [
    "best_gb.fit(X_train_prepared, y_train)\n",
    "y_pred_gb = best_gb.predict(X_test_prepared)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Model - MAE: {mae_gb}, MSE: {mse_gb}, R2: {r2_gb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge and Lasso Regression (Regularized Linear Models)\n",
    "- Scaler: StandardScaler.\n",
    "- Tuning: alpha for regularization strength.\n",
    "- Search Method: GridSearchCV, since it works well with single parameters.\n",
    "- Pipeline: Required for scaling.\n",
    "- Cross-Validation: Improves generalization.\n",
    "- Use similar code as for Linear Regression above, substituting Ridge() or Lasso() as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.82827e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.81376e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.85978e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.60378e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21549e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Ridge Regression: {'alpha': 0.1, 'solver': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.82827e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.81376e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.85978e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.60378e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21549e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.82096e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80666e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.85173e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59324e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19275e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.82096e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80666e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.85173e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59324e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19275e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78164e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.76509e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.81442e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.53885e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.07765e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78164e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.76509e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.81442e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.53885e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.07765e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80858e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Ridge Regression\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1.0, 10.0],\n",
    "    'solver': ['auto', 'svd', 'cholesky']\n",
    "}\n",
    "\n",
    "grid_search_ridge = GridSearchCV(Ridge(), param_grid_ridge, cv=5, scoring='r2')\n",
    "grid_search_ridge.fit(X_train_prepared, y_train)\n",
    "print(\"Best params for Ridge Regression:\", grid_search_ridge.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Model - MAE: 482900.4766879166, MSE: 2421393998157.9087, R2: 0.4228855284528211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80858e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "# Best model setup and evaluation\n",
    "best_ridge = Ridge(\n",
    "    alpha=grid_search_ridge.best_params_['alpha'],\n",
    "    solver=grid_search_ridge.best_params_['solver']\n",
    ")\n",
    "best_ridge.fit(X_train_prepared, y_train)\n",
    "y_pred_ridge = best_ridge.predict(X_test_prepared)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "print(f\"Ridge Regression Model - MAE: {mae_ridge}, MSE: {mse_ridge}, R2: {r2_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Regressor (KNN)\n",
    "- Scaler: StandardScaler, since KNN is sensitive to the scale of data.\n",
    "- Tuning: n_neighbors, weights.\n",
    "- Search Method: GridSearchCV is feasible with fewer parameters.\n",
    "- Pipeline: Required for scaling.\n",
    "- Cross-Validation: Improves reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for KNN: {'model__n_neighbors': 3, 'model__weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "pipeline_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "param_grid_knn = {\n",
    "    'model__n_neighbors': [3, 5, 7],\n",
    "    'model__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(pipeline_knn, param_grid_knn, cv=5, scoring='r2')\n",
    "grid_search_knn.fit(X, y)\n",
    "print(\"Best params for KNN:\", grid_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test R^2 Score: 0.6266622180527488\n"
     ]
    }
   ],
   "source": [
    "# Test on best model\n",
    "best_knn_model = grid_search_knn.best_estimator_\n",
    "y_pred_knn = best_knn_model.predict(X_test)\n",
    "print(\"KNN Test R^2 Score:\", r2_score(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net\n",
    "- Scaler: StandardScaler.\n",
    "- Tuning: alpha, l1_ratio to balance L1 (Lasso) and L2 (Ridge).\n",
    "- Search Method: GridSearchCV for fine-tuning.\n",
    "- Pipeline: Required for scaling.\n",
    "- Cross-Validation: Helps generalize predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for ElasticNet: {'model__alpha': 0.1, 'model__l1_ratio': 0.1}\n"
     ]
    }
   ],
   "source": [
    "pipeline_elastic = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', ElasticNet())\n",
    "])\n",
    "\n",
    "param_grid_elastic = {\n",
    "    'model__alpha': [0.1, 1.0, 10.0],\n",
    "    'model__l1_ratio': [0.1, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "grid_search_elastic = GridSearchCV(pipeline_elastic, param_grid_elastic, cv=5, scoring='r2')\n",
    "grid_search_elastic.fit(X, y)\n",
    "print(\"Best params for ElasticNet:\", grid_search_elastic.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Test R^2 Score: 0.5420913906336453\n"
     ]
    }
   ],
   "source": [
    "# Test on best model\n",
    "best_elastic_model = grid_search_elastic.best_estimator_\n",
    "y_pred_elastic = best_elastic_model.predict(X_test)\n",
    "print(\"ElasticNet Test R^2 Score:\", r2_score(y_test, y_pred_elastic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "- Scaler: StandardScaler.\n",
    "- Tuning: C, epsilon for the penalty term and tolerance.\n",
    "- Search Method: GridSearchCV for systematic tuning.\n",
    "- Pipeline: Required for scaling.\n",
    "- Cross-Validation: Ensures stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for SVM: {'model__C': 10.0, 'model__epsilon': 0.1}\n"
     ]
    }
   ],
   "source": [
    "pipeline_svr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', SVR())\n",
    "])\n",
    "\n",
    "param_grid_svr = {\n",
    "    'model__C': [0.1, 1.0, 10.0],\n",
    "    'model__epsilon': [0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "grid_search_svr = GridSearchCV(pipeline_svr, param_grid_svr, cv=5, scoring='r2')\n",
    "grid_search_svr.fit(X, y)\n",
    "print(\"Best params for SVM:\", grid_search_svr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test R^2 Score: -0.04403421492664572\n"
     ]
    }
   ],
   "source": [
    "# Test on best model\n",
    "best_svr_model = grid_search_svr.best_estimator_\n",
    "y_pred_svr = best_svr_model.predict(X_test)\n",
    "print(\"SVM Test R^2 Score:\", r2_score(y_test, y_pred_svr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation:\n",
    "- Cross-validation gives a more reliable estimate of model performance by testing on different subsets of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Cross-Validation Score: 0.5186506965955372\n",
      "Ridge Regression Cross-Validation Score: 0.519377628119685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+14, tolerance: 2.366e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+14, tolerance: 2.298e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e+14, tolerance: 2.175e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+14, tolerance: 2.159e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.618e+13, tolerance: 2.210e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Cross-Validation Score: 0.5186370660999051\n",
      "Decision Tree Cross-Validation Score: 0.3144771082437415\n",
      "Random Forest Cross-Validation Score: 0.564773894423067\n",
      "Gradient Boosting Cross-Validation Score: 0.5803685994255808\n",
      "K-Nearest Neighbors Cross-Validation Score: 0.35455771879994175\n",
      "Elastic Net Cross-Validation Score: 0.5075502127554798\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate for each model\n",
    "for model_name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train_prepared, y_train, cv=5)\n",
    "    print(f\"{model_name} Cross-Validation Score: {cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation divides the training data into several smaller sets, training on some while testing on others to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Results:\n",
    "- Linear Regression Cross-Validation Score: -2.23e+23\n",
    "  This extremely low score suggests that the linear regression model is overfitting during cross-validation, failing to generalize across different subsets of the data.\n",
    "\n",
    "- Ridge Regression Cross-Validation Score: 0.519\n",
    "  The ridge regression cross-validation score of 51.9% shows slightly better generalization than linear regression, but still not exceptional.\n",
    "\n",
    "- Lasso Regression Cross-Validation Score: 0.519\n",
    "  Similar to ridge regression, the lasso model also performs decently with a 51.9% cross-validation score, but doesn’t outperform ridge regression or other models.\n",
    "\n",
    "- Decision Tree Cross-Validation Score: 0.296\n",
    "  The decision tree model's poor cross-validation score (29.6%) indicates overfitting, where the model is performing well on the training data but failing to generalize to unseen data.\n",
    "\n",
    "- Random Forest Cross-Validation Score: 0.564\n",
    "  The random forest model achieves a 56.4% cross-validation score, showing good generalization and performance across different subsets of the data.\n",
    "\n",
    "- Gradient Boosting Cross-Validation Score: 0.584\n",
    "  The gradient boosting model performs best during cross-validation, with a score of 58.4%, confirming its overall strength in predicting listing prices.\n",
    "\n",
    "- K-Nearest Neighbors Cross-Validation Score: 0.508\n",
    "  The KNN model achieves a score of 50.8%, which is relatively good but still not as strong as random forest or gradient boosting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation:\n",
    "Now, we assess each model’s accuracy using metrics that measure how close the predictions are to actual prices.\n",
    "\n",
    "Evaluation Metrics:\n",
    "\n",
    "- Mean Absolute Error (MAE) and Mean Squared Error (MSE) show prediction accuracy. Lower values mean better performance.\n",
    "- R-squared measures how well the model explains the price variation; closer to 1 is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 229055.36684885834\n",
      "Mean Squared Error: 251496287431.15927\n",
      "R-squared: 0.6572810105926945\n"
     ]
    }
   ],
   "source": [
    "# Define and train the Gradient Boosting model\n",
    "best_model = GradientBoostingRegressor()  \n",
    "best_model.fit(X_train_prepared, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model.predict(X_test_prepared)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics tell us how far the predictions are from real prices and how well the model explains price differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Error (MAE): 230,092.19**\n",
    "This is the average absolute error in the predictions. On average, the predicted listing prices are off by approximately $230,092 from the actual values.\n",
    "While this provides an intuitive sense of error, it doesn’t penalize larger errors more heavily than smaller ones (like MSE does).\n",
    "\n",
    "**Mean Squared Error (MSE): 251,119,327,373.67**\n",
    "MSE squares the errors, making it sensitive to large outliers. A high MSE indicates some predictions may be quite far from the actual values, possibly due to certain properties with very high or low prices.\n",
    "MSE can be useful to emphasize large errors, though it is less interpretable in dollar terms than MAE.\n",
    "\n",
    "**R-squared (R²): 0.6578**\n",
    "R² is the proportion of variance in the target variable (listing price) explained by the model.\n",
    "An R² of 0.6578 means the model explains approximately 65.78% of the variance in property listing prices. This suggests that while the model captures a good amount of variance, there is still room for improvement.\n",
    "\n",
    "The model performs reasonably well but may have difficulty predicting certain extreme listing prices. Given the real estate context, this level of accuracy is a good start but may need refinement if lower error tolerances are required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning:\n",
    "- We improve the model by adjusting its settings, like the number of trees in a forest. This helps the model learn better patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20]\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_prepared, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV finds the best parameters to boost accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning revealed that a maximum depth of 10 and 200 estimators for the random forest model lead to the best performance. This combination prevents overfitting while capturing enough complexity in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression, Ridge Regression, Lasso Regression\n",
    "While these models don't have many hyperparameters to tune, Ridge and Lasso have a hyperparameter for regularization strength (alpha). For Linear Regression, no hyperparameter tuning is needed, but for Ridge and Lasso, we can tune alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Ridge: {'alpha': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+13, tolerance: 2.366e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+13, tolerance: 2.298e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+13, tolerance: 2.175e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+13, tolerance: 2.159e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.720e+12, tolerance: 2.210e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+13, tolerance: 2.366e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+13, tolerance: 2.298e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+13, tolerance: 2.175e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+13, tolerance: 2.159e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.721e+12, tolerance: 2.210e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+13, tolerance: 2.366e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+13, tolerance: 2.298e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+13, tolerance: 2.175e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e+13, tolerance: 2.159e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.729e+12, tolerance: 2.210e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Lasso: {'alpha': 100}\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters for Ridge Regression\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1, 10, 100]  # Regularization strength\n",
    "}\n",
    "grid_search_ridge = GridSearchCV(Ridge(), param_grid_ridge, cv=5)\n",
    "grid_search_ridge.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for Ridge:\", grid_search_ridge.best_params_)\n",
    "\n",
    "# Tuning hyperparameters for Lasso Regression\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.1, 1, 10, 100]  # Regularization strength\n",
    "}\n",
    "grid_search_lasso = GridSearchCV(Lasso(), param_grid_lasso, cv=5)\n",
    "grid_search_lasso.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for Lasso:\", grid_search_lasso.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The optimal regularization strength for Ridge regression is found to be 100, suggesting a strong regularization effect, which helps prevent overfitting.\n",
    "- Similarly, for Lasso, the best regularization strength is also 100. This large value implies that Lasso is applying substantial regularization, which may lead to sparse solutions (where coefficients are driven to zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor \n",
    "The Decision Tree Regressor has hyperparameters like max_depth, min_samples_split, and min_samples_leaf that can be tuned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Decision Tree: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters for Decision Tree\n",
    "param_grid_tree = {\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "grid_search_tree = GridSearchCV(DecisionTreeRegressor(), param_grid_tree, cv=5)\n",
    "grid_search_tree.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for Decision Tree:\", grid_search_tree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Decision Trees, the best model is found with a max_depth of 10, meaning the tree is not overly deep, reducing the risk of overfitting. The min_samples_split of 10 ensures that nodes with fewer than 10 samples will not split further, promoting generalization. The min_samples_leaf of 5 ensures each leaf has at least 5 samples, which helps avoid creating overly specific branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) \n",
    "For KNN, the hyperparameter n_neighbors can be tuned. We might also want to tune weights (whether the algorithm should use uniform or distance-based weighting) and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for KNN: {'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters for K-Nearest Neighbors (KNN)\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 10, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "grid_search_knn = GridSearchCV(KNeighborsRegressor(), param_grid_knn, cv=5)\n",
    "grid_search_knn.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for KNN:\", grid_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbors model performs best with the Manhattan distance metric (instead of Euclidean), meaning it calculates distance by summing the absolute differences. The best number of neighbors is 10, indicating that the predictions are based on the average of the 10 nearest neighbors. The uniform weights suggest that all neighbors are equally important in predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor\n",
    "For Gradient Boosting, we can tune n_estimators, learning_rate, max_depth, and other parameters to improve the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters for Gradient Boosting\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search_gb = GridSearchCV(GradientBoostingRegressor(), param_grid_gb, cv=5)\n",
    "grid_search_gb.fit(X_train_prepared, y_train)\n",
    "print(\"Best Parameters for Gradient Boosting:\", grid_search_gb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gradient Boosting, the best combination is a moderate learning_rate of 0.1, which balances the model's ability to learn without overfitting. The max_depth of 3 ensures that the trees built in each boosting iteration are relatively shallow, reducing complexity. The n_estimators of 100 indicates the number of trees in the ensemble, suggesting that the model needs a decent number of trees for strong predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Hyperparamter Tuning for Each Model\n",
    "After performing grid search and identifying the best hyperparameters for each model, we can retrain each model using these optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-train each model with the best hyperparameters\n",
    "\n",
    "# For Ridge\n",
    "best_ridge = Ridge(alpha=grid_search_ridge.best_params_['alpha'])\n",
    "best_ridge.fit(X_train_prepared, y_train)\n",
    "\n",
    "# For Lasso\n",
    "best_lasso = Lasso(alpha=grid_search_lasso.best_params_['alpha'])\n",
    "best_lasso.fit(X_train_prepared, y_train)\n",
    "\n",
    "# For Decision Tree\n",
    "best_tree = DecisionTreeRegressor(\n",
    "    max_depth=grid_search_tree.best_params_['max_depth'],\n",
    "    min_samples_split=grid_search_tree.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=grid_search_tree.best_params_['min_samples_leaf']\n",
    ")\n",
    "best_tree.fit(X_train_prepared, y_train)\n",
    "\n",
    "# For KNN\n",
    "best_knn = KNeighborsRegressor(\n",
    "    n_neighbors=grid_search_knn.best_params_['n_neighbors'],\n",
    "    weights=grid_search_knn.best_params_['weights'],\n",
    "    metric=grid_search_knn.best_params_['metric']\n",
    ")\n",
    "best_knn.fit(X_train_prepared, y_train)\n",
    "\n",
    "# For Gradient Boosting\n",
    "best_gb = GradientBoostingRegressor(\n",
    "    n_estimators=grid_search_gb.best_params_['n_estimators'],\n",
    "    learning_rate=grid_search_gb.best_params_['learning_rate'],\n",
    "    max_depth=grid_search_gb.best_params_['max_depth']\n",
    ")\n",
    "best_gb.fit(X_train_prepared, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Each Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Model - MAE: 482900.4766879166, MSE: 2421393998157.9087, R2: 0.4228855284528211\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_lasso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRidge Model - MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae_ridge\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse_ridge\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, R2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_ridge\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# For Lasso\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m y_pred_lasso \u001b[38;5;241m=\u001b[39m best_lasso\u001b[38;5;241m.\u001b[39mpredict(X_test_prepared)\n\u001b[1;32m     10\u001b[0m mae_lasso \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, y_pred_lasso)\n\u001b[1;32m     11\u001b[0m mse_lasso \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred_lasso)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_lasso' is not defined"
     ]
    }
   ],
   "source": [
    "# For Ridge\n",
    "y_pred_ridge = best_ridge.predict(X_test_prepared)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "print(f\"Ridge Model - MAE: {mae_ridge}, MSE: {mse_ridge}, R2: {r2_ridge}\")\n",
    "\n",
    "# For Lasso\n",
    "y_pred_lasso = best_lasso.predict(X_test_prepared)\n",
    "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "print(f\"Lasso Model - MAE: {mae_lasso}, MSE: {mse_lasso}, R2: {r2_lasso}\")\n",
    "\n",
    "# For Decision Tree\n",
    "y_pred_tree = best_tree.predict(X_test_prepared)\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree Model - MAE: {mae_tree}, MSE: {mse_tree}, R2: {r2_tree}\")\n",
    "\n",
    "# For KNN\n",
    "y_pred_knn = best_knn.predict(X_test_prepared)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "print(f\"KNN Model - MAE: {mae_knn}, MSE: {mse_knn}, R2: {r2_knn}\")\n",
    "\n",
    "# For Gradient Boosting\n",
    "y_pred_gb = best_gb.predict(X_test_prepared)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Model - MAE: {mae_gb}, MSE: {mse_gb}, R2: {r2_gb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation and Feature Importance\n",
    "After tuning, we examine what features (like square footage) the model considers most important in predicting price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Feature  Importance\n",
      "7                               sqft    0.502489\n",
      "2                              baths    0.188141\n",
      "6                           lot_sqft    0.183114\n",
      "1                               beds    0.031686\n",
      "0                         year_built    0.022063\n",
      "8                            stories    0.019647\n",
      "5                             garage    0.019256\n",
      "3                         baths_full    0.010316\n",
      "9                          sold_year    0.009504\n",
      "10                        sold_month    0.004228\n",
      "19                type_single_family    0.004080\n",
      "17                       type_mobile    0.003149\n",
      "15                         type_farm    0.001041\n",
      "4                         baths_half    0.000887\n",
      "16                         type_land    0.000400\n",
      "18                        type_other    0.000000\n",
      "21                    type_townhouse    0.000000\n",
      "20                    type_townhomes    0.000000\n",
      "11                        type_condo    0.000000\n",
      "14                       type_condos    0.000000\n",
      "13  type_condo_townhome_rowhome_coop    0.000000\n",
      "12               type_condo_townhome    0.000000\n",
      "22                    status_encoded    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract feature importance for the gradient boosting\n",
    "feature_importances = best_model.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(features, feature_importances)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance in Predicting Listing Price\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows which features matter most, helping us understand what affects price most (e.g., square footage or bathrooms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance Interpretation\n",
    "\n",
    "- Square Footage is the most influential factor, contributing over 50% to the model’s predictive power, indicating a strong correlation with listing price.\n",
    "- Bathrooms and Lot Size together account for about 37% of feature importance, suggesting that larger lot sizes and additional bathrooms significantly impact property value.\n",
    "- Bedrooms and Year Built have modest influence, reflecting that while additional bedrooms and newer construction add value, they are secondary compared to square footage and lot characteristics.\n",
    "- Garage Presence and Property Stories provide minor but noticeable predictive value, indicating some buyer preference for these features.\n",
    "- Property Type and Sale Date contribute minimally, showing limited impact on listing price within this dataset and market context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 229632.6085441442\n",
      "Mean Squared Error: 250634549622.3414\n",
      "R-squared: 0.6584553178319335\n"
     ]
    }
   ],
   "source": [
    "# Prediction using the best model\n",
    "y_pred = best_gb.predict(X_test_prepared)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Top 3 ML Models for Better Predicition Accuracy:\n",
    "\n",
    "In this section, we will focus on improving the top 3 models: Random Forest, Gradient Boosting, and Ridge Regression. These models were chosen because they showed the highest baseline scores during our initial model evaluation. Our goal is to increase the accuracy of these models to at least 80% by using additional preprocessing techniques, dimensionality reduction (PCA), and feature scaling (RobustScaler).\n",
    "\n",
    "We’ll also create visualizations to better understand our models' performance, including ROC-AUC curves and a correlation matrix for feature selection insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing with RobustScaler\n",
    "\n",
    "RobustScaler is helpful when dealing with data that may have outliers, as it scales the data using the median and the interquartile range. This can make models more robust to extreme values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction with PCA\n",
    "To reduce noise and potentially improve model performance, we’ll apply Principal Component Analysis (PCA). PCA helps in selecting the most important components (features) for our models, which might improve their efficiency and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components after PCA: 1\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA and keep enough components to explain 95% of the variance\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Print the number of components\n",
    "print(f\"Number of components after PCA: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving and Evaluating Models\n",
    "We’ll now train our three models using the scaled and PCA-transformed data, then evaluate each model's performance using Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R2) scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gradient Boosting on PCA-transformed data\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train_pca, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model Performance:\n",
      "Mean Absolute Error: 412112.0023959897\n",
      "Mean Squared Error: 682662339290.3176\n",
      "R-squared: 0.06972246223695977\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting Model Performance:\")\n",
    "print(f\"Mean Absolute Error: {mae_gb}\")\n",
    "print(f\"Mean Squared Error: {mse_gb}\")\n",
    "print(f\"R-squared: {r2_gb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest on PCA-transformed data\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train_pca, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Performance:\n",
      "Mean Absolute Error: 435451.6607232145\n",
      "Mean Squared Error: 848284112909.354\n",
      "R-squared: -0.15597362043025975\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Model Performance:\")\n",
    "print(f\"Mean Absolute Error: {mae_rf}\")\n",
    "print(f\"Mean Squared Error: {mse_rf}\")\n",
    "print(f\"R-squared: {r2_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Ridge Regression on PCA-transformed data\n",
    "ridge_model = Ridge(random_state=42)\n",
    "ridge_model.fit(X_train_pca, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Model Performance:\n",
      "Mean Absolute Error: 413869.88875899743\n",
      "Mean Squared Error: 635821716213.0349\n",
      "R-squared: 0.1335531102684897\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge Regression Model Performance:\")\n",
    "print(f\"Mean Absolute Error: {mae_ridge}\")\n",
    "print(f\"Mean Squared Error: {mse_ridge}\")\n",
    "print(f\"R-squared: {r2_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The updated models show mixed performance, with R-squared values far below our goal of 80%. The Gradient Boosting model has the best (though still low) R-squared value at approximately 0.07, compared to the baseline of around 0.66 initially. Given the minimal improvement or negative changes, it would indeed be worth exploring RandomizedSearchCV for hyperparameter tuning alongside MinMaxScaler to normalize the features, which could further refine model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3 Using MinMaxScaler and RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply MinMaxScaler\n",
    "The MinMaxScaler scales each feature to a range between 0 and 1, which can help improve model training by ensuring features have similar scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and apply MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV for Hyperparameter Tuning\n",
    "Using RandomizedSearchCV will allow us to test a range of hyperparameters more efficiently than a Grid Search, which is beneficial given the current models' poor R-squared scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for RandomizedSearchCV\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Gradient Boosting: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 3, 'learning_rate': 0.1}\n",
      "Best R-squared score for Gradient Boosting: 0.5869963423907759\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gradient Boosting model\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV with 10 iterations for efficient tuning\n",
    "random_search_gb = RandomizedSearchCV(estimator=gb_model, param_distributions=param_grid_gb,\n",
    "                                      n_iter=10, scoring='r2', cv=5, random_state=42, n_jobs=-1)\n",
    "# Fit model\n",
    "random_search_gb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters for Gradient Boosting:\", random_search_gb.best_params_)\n",
    "print(\"Best R-squared score for Gradient Boosting:\", random_search_gb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for RandomizedSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 10}\n",
      "Best R-squared score for Random Forest: 0.5933659401616825\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf_model, param_distributions=param_grid_rf,\n",
    "                                      n_iter=10, scoring='r2', cv=5, random_state=42, n_jobs=-1)\n",
    "# Fit model\n",
    "random_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters for Random Forest:\", random_search_rf.best_params_)\n",
    "print(\"Best R-squared score for Random Forest:\", random_search_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for RandomizedSearchCV\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_grid_ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ridge_model \u001b[38;5;241m=\u001b[39m Ridge(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Set up RandomizedSearchCV\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m random_search_ridge \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mridge_model, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid_ridge,\n\u001b[1;32m      6\u001b[0m                                          n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m random_search_ridge\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param_grid_ridge' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Ridge Regression model\n",
    "ridge_model = Ridge(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search_ridge = RandomizedSearchCV(estimator=ridge_model, param_distributions=param_grid_ridge,\n",
    "                                         n_iter=10, scoring='r2', cv=5, random_state=42, n_jobs=-1)\n",
    "# Fit model\n",
    "random_search_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters for Ridge Regression:\", random_search_ridge.best_params_)\n",
    "print(\"Best R-squared score for Ridge Regression:\", random_search_ridge.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Findings "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohort_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
